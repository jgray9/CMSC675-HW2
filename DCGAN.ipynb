{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "NOISE_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Create Grumpy Cat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dir, transform = transforms.ToTensor()):\n",
    "        self.total_imgs: list[torch.Tensor] = []\n",
    "        for file in os.listdir(dir):\n",
    "            self.total_imgs.append( Image.open(dir + '/' + file) )\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.total_imgs)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Image.Image:\n",
    "        return self.transform(self.total_imgs[idx])\n",
    "\n",
    "dataset = CustomDataset(\"grumpifyCat\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(mode: str) -> nn.Module:\n",
    "    if mode == \"simple\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((64, 64), transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    elif mode == \"deluxe\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((64, 64), transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.RandomGrayscale(0.2),\n",
    "            transforms.RandomRotation(180),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Implement the Discriminator of the DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # size_out = (size_in + 2 * padding - kernel) / stride + 1\n",
    "        self.layers = nn.Sequential(\n",
    "            # INPUT 3x64x64\n",
    "            nn.Conv2d(  3,  32, kernel_size=4, stride=2, padding=1), # 32x32x32\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d( 32,  64, kernel_size=4, stride=2, padding=1), # 64x16x16\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d( 64, 128, kernel_size=4, stride=2, padding=1), # 128x8x8\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), # 256x4x4\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 1, kernel_size=6, stride=2, padding=1), # 1x1x1\n",
    "        )\n",
    "    \n",
    "    def forward(self, z) -> torch.Tensor:\n",
    "        return self.layers(z).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Implement the Generator of the DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100):\n",
    "        super(Generator, self).__init__()\n",
    "        # size_out = (size_in - 1) * stride - 2 * padding + kernel\n",
    "        self.layers = nn.Sequential(\n",
    "            # INPUT nsx1x1\n",
    "            nn.ConvTranspose2d(noise_size, 256, kernel_size=6, stride=2, padding=1),    # 256x4x4\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),           # 128x8x8\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),            # 64x16x16\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d( 64, 32, kernel_size=4, stride=2, padding=1),            # 32x32x32\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d( 32,  3, kernel_size=4, stride=2, padding=1),            # 3x64x64\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, z) -> torch.Tensor:\n",
    "        return self.layers(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss - Discriminator: 2.32     Generator: 28.79   \n",
      "Loss - Discriminator: 22.05    Generator: 42.72   \n",
      "Loss - Discriminator: 1.87     Generator: 38.67   \n",
      "Loss - Discriminator: 5.96     Generator: 3.95    \n",
      "Loss - Discriminator: 8.49     Generator: 12.82   \n",
      "Loss - Discriminator: 0.98     Generator: 21.01   \n",
      "Loss - Discriminator: 0.76     Generator: 11.69   \n",
      "Loss - Discriminator: 0.86     Generator: 8.49    \n",
      "Loss - Discriminator: 0.70     Generator: 12.40   \n",
      "Loss - Discriminator: 0.37     Generator: 13.39   \n",
      "Loss - Discriminator: 0.51     Generator: 10.81   \n",
      "Loss - Discriminator: 0.79     Generator: 10.11   \n",
      "Loss - Discriminator: 0.50     Generator: 11.47   \n",
      "Loss - Discriminator: 0.54     Generator: 10.95   \n",
      "Loss - Discriminator: 0.21     Generator: 9.91    \n",
      "Loss - Discriminator: 0.34     Generator: 10.63   \n",
      "Loss - Discriminator: 0.32     Generator: 11.72   \n",
      "Loss - Discriminator: 0.11     Generator: 12.84   \n",
      "Loss - Discriminator: 0.22     Generator: 12.27   \n",
      "Loss - Discriminator: 0.31     Generator: 10.30   \n",
      "Loss - Discriminator: 0.12     Generator: 11.32   \n",
      "Loss - Discriminator: 0.27     Generator: 12.00   \n",
      "Loss - Discriminator: 0.39     Generator: 10.57   \n",
      "Loss - Discriminator: 0.06     Generator: 11.32   \n",
      "Loss - Discriminator: 0.20     Generator: 12.69   \n",
      "Loss - Discriminator: 0.21     Generator: 11.61   \n",
      "Loss - Discriminator: 0.04     Generator: 10.99   \n",
      "Loss - Discriminator: 0.19     Generator: 11.95   \n",
      "Loss - Discriminator: 0.19     Generator: 11.42   \n",
      "Loss - Discriminator: 0.06     Generator: 10.25   \n",
      "Loss - Discriminator: 0.15     Generator: 10.81   \n",
      "Loss - Discriminator: 0.16     Generator: 10.79   \n",
      "Loss - Discriminator: 0.04     Generator: 10.50   \n",
      "Loss - Discriminator: 0.12     Generator: 10.51   \n",
      "Loss - Discriminator: 0.13     Generator: 10.21   \n",
      "Loss - Discriminator: 0.05     Generator: 12.31   \n",
      "Loss - Discriminator: 0.13     Generator: 10.21   \n",
      "Loss - Discriminator: 0.22     Generator: 13.03   \n",
      "Loss - Discriminator: 0.09     Generator: 8.65    \n",
      "Loss - Discriminator: 0.31     Generator: 13.33   \n",
      "Loss - Discriminator: 0.22     Generator: 8.28    \n",
      "Loss - Discriminator: 0.21     Generator: 11.92   \n",
      "Loss - Discriminator: 0.18     Generator: 8.64    \n",
      "Loss - Discriminator: 0.18     Generator: 9.22    \n",
      "Loss - Discriminator: 0.05     Generator: 11.35   \n",
      "Loss - Discriminator: 0.11     Generator: 8.44    \n",
      "Loss - Discriminator: 0.23     Generator: 12.60   \n",
      "Loss - Discriminator: 0.08     Generator: 8.47    \n",
      "Loss - Discriminator: 0.35     Generator: 13.82   \n",
      "Loss - Discriminator: 0.27     Generator: 8.78    \n",
      "Loss - Discriminator: 0.27     Generator: 13.28   \n",
      "Loss - Discriminator: 0.13     Generator: 11.30   \n",
      "Loss - Discriminator: 0.11     Generator: 10.40   \n",
      "Loss - Discriminator: 0.03     Generator: 12.40   \n",
      "Loss - Discriminator: 0.10     Generator: 9.62    \n",
      "Loss - Discriminator: 0.13     Generator: 10.64   \n",
      "Loss - Discriminator: 0.05     Generator: 9.28    \n",
      "Loss - Discriminator: 0.12     Generator: 11.61   \n",
      "Loss - Discriminator: 0.12     Generator: 7.46    \n",
      "Loss - Discriminator: 0.32     Generator: 15.22   \n",
      "Loss - Discriminator: 0.55     Generator: 4.75    \n",
      "Loss - Discriminator: 0.98     Generator: 10.58   \n",
      "Loss - Discriminator: 0.17     Generator: 10.44   \n",
      "Loss - Discriminator: 0.11     Generator: 5.67    \n",
      "Loss - Discriminator: 0.31     Generator: 8.10    \n",
      "Loss - Discriminator: 0.06     Generator: 10.02   \n",
      "Loss - Discriminator: 0.24     Generator: 5.37    \n",
      "Loss - Discriminator: 0.21     Generator: 5.11    \n",
      "Loss - Discriminator: 0.12     Generator: 8.62    \n",
      "Loss - Discriminator: 0.18     Generator: 6.92    \n",
      "Loss - Discriminator: 0.04     Generator: 4.61    \n",
      "Loss - Discriminator: 0.21     Generator: 6.97    \n",
      "Loss - Discriminator: 0.07     Generator: 8.41    \n",
      "Loss - Discriminator: 0.17     Generator: 4.96    \n",
      "Loss - Discriminator: 0.22     Generator: 4.90    \n",
      "Loss - Discriminator: 0.20     Generator: 8.92    \n",
      "Loss - Discriminator: 0.26     Generator: 6.49    \n",
      "Loss - Discriminator: 0.03     Generator: 4.08    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m iteration % \u001b[32m200\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     61\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoss - Discriminator: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD_total_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Generator: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mtraining_loop\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m     35\u001b[39m D_total_loss: torch.Tensor = (D_real_loss + D_fake_loss).sum().div(n)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iteration % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mD_total_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     d_optimizer.step()\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# TRAIN GENERATOR\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/CMSC675-HW2/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/CMSC675-HW2/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:346\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    337\u001b[39m inputs = (\n\u001b[32m    338\u001b[39m     (inputs,)\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch.Tensor, graph.GradientEdge))\n\u001b[32m   (...)\u001b[39m\u001b[32m    342\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    343\u001b[39m )\n\u001b[32m    345\u001b[39m grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m grad_tensors_ = \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/CMSC675-HW2/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:221\u001b[39m, in \u001b[36m_make_grads\u001b[39m\u001b[34m(outputs, grads, is_grads_batched)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch.Tensor)\n\u001b[32m    220\u001b[39m         new_grads.append(\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m         )\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    224\u001b[39m     new_grads.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def training_loop(dataloader: DataLoader):\n",
    "    # Create generators and discriminators\n",
    "    generator = Generator(NOISE_SIZE)\n",
    "    discriminator = Discriminator()\n",
    "\n",
    "    # Create optimizers for the generators and discriminators\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=LEARNING_RATE)\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        iteration = 0\n",
    "        for data in dataloader:\n",
    "            n = data.shape[0]\n",
    "            # \n",
    "            # TRAIN DISCRIMINATOR\n",
    "            # \n",
    "            \n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # 1. Compute the discriminator loss on real images\n",
    "            D_real_pred: torch.Tensor = discriminator(data)\n",
    "            D_real_loss: torch.Tensor = (1 - D_real_pred).pow(2)\n",
    "\n",
    "            # 2. Sample noise\n",
    "            noise: torch.Tensor = torch.rand((n,NOISE_SIZE,1,1))\n",
    "\n",
    "            # 3. Generate fake images from the noise\n",
    "            fake_images: torch.Tensor = generator(noise)\n",
    "\n",
    "            # 4. Compute the discriminator loss on the fake images\n",
    "            D_fake_pred: torch.Tensor = discriminator(fake_images)\n",
    "            D_fake_loss: torch.Tensor = (-1 - D_fake_pred).pow(2)\n",
    "\n",
    "            # 5. Compute total loss\n",
    "            D_total_loss: torch.Tensor = (D_real_loss + D_fake_loss).sum().div(n)\n",
    "            if iteration % 2 == 0:\n",
    "                D_total_loss.backward()\n",
    "                d_optimizer.step()\n",
    "\n",
    "            # \n",
    "            # TRAIN GENERATOR\n",
    "            # \n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            # 1. Sample noise\n",
    "            noise: torch.Tensor = torch.rand((n,NOISE_SIZE,1,1))\n",
    "\n",
    "            # 2. Generate fake images from the noise\n",
    "            fake_images: torch.Tensor = generator(noise)\n",
    "\n",
    "            # 3. Compute the generator loss\n",
    "            D_gen_pred: torch.Tensor = discriminator(fake_images)\n",
    "            G_loss: torch.Tensor = (1 - D_gen_pred).pow(2).sum().div(n)\n",
    "\n",
    "            G_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Print each loss every 200 iterations\n",
    "            if iteration % 200 == 0:\n",
    "                print(f\"Loss - Discriminator: {D_total_loss:<8.2f} Generator: {G_loss:<8.2f}\")\n",
    "\n",
    "training_loop(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
